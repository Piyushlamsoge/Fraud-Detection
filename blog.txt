---

Simplifying Machine Learning with ATOM ML: A Comprehensive Guide and Real-World Example
Atom is an open-source, free-to-use machine learning (ML) framework developed by the Hugging Face team, which aims to make ML accessible to everyone. Atom is built on top of PyTorch and provides a simple, yet powerful API for training and deploying ML models. In this blog, we will dive into the Atom ML module and explore its features with a real-world example.
Atom ML is a module within the Atom framework that provides an easy-to-use interface for building and training ML models. It comes with a pre-built set of models and allows you to build your custom models using its building blocks. Atom ML also includes a set of tools for data preprocessing, training, and evaluation, making it a complete solution for ML workflows.

---

Features and Benefits
The ATOM ML module is designed to make machine learning more accessible to developers and data scientists. Some of its features and benefits include:
Simplifies machine learning tasks: The ATOM ML module provides a simple and easy-to-use API that abstracts away much of the complexity of machine learning tasks. This makes it easier for developers and data scientists to build and deploy machine learning models.
Supports a variety of machine learning tasks: The module supports a wide range of machine learning tasks, including classification, regression, sequence tagging, and more.
Provides pre-trained models: The module comes with pre-trained models for various tasks, which can be fine-tuned on specific datasets to achieve high-performance.
Supports multiple frameworks: The module is designed to work with multiple machine learning frameworks, including PyTorch and TensorFlow.
Offers easy deployment: The ATOM ML module provides an easy way to deploy machine learning models, either locally or in the cloud.

---

Example
In This example shows how to use ATOM to solve a binary classification problem. Additonnaly, we'll perform a variety of data cleaning steps to prepare the data for modelling.

The data used is a variation on the Australian weather dataset from Kaggle. You can download it from here. The goal of this dataset is to predict whether or not it will rain tomorrow training a binary classifier on target RainTomorrow
Load the data
# Import packages
import pandas as pd
from atom import ATOMClassifier
# Load data
X = pd.read_csv("./datasets/weatherAUS.csv")

# Let's have a look
X.head()
In the code snippet above, we have imported the necessary packages required to load and analyze data. We have loaded a weather dataset in CSV format using the read_csv() method provided by the Pandas library. Furthermore, we have used the head() method, which is also a part of the Pandas library, to display the first five rows of the dataset in order to get an initial sense of the data
Run the pipeline
# Call atom using only 5% of the complete dataset (for explanatory purposes)
atom = ATOMClassifier(X, "RainTomorrow", n_rows=0.05, n_jobs=8, verbose=2)
The code above is using the ATOMClassifier class from the ATOM ML module to initialize a new classification model. It takes in the following arguments:
X: The input data to be used for training the model.
"RainTomorrow": The name of the target column in the input data, which represents the labels or classes to be predicted.
n_rows=0.05: The number of rows to use from the input data for training and testing purposes. In this case, only 5% of the complete dataset will be used for demonstration purposes.
n_jobs=8: The number of CPU cores to use during the model training process.
verbose=2: The level of detail to print during the training process. In this case, verbose level 2 will display a progress bar during the training process.

Handling missing values
# Impute missing values
atom.impute(strat_num="median", strat_cat="drop", max_nan_rows=0.8)
The code above demonstrates the use of the impute() method of the ATOMClassifier class to handle missing values in the input data. We are passing in three arguments to the impute() method:
strat_num="median": This argument specifies the imputation strategy to use for numerical columns that contain missing values. In this case, we are using the median value to fill in missing numerical values.
strat_cat="drop": This argument specifies the imputation strategy to use for categorical columns that contain missing values. In this case, we are dropping any rows that contain missing categorical values, as it is not appropriate to impute categorical values in most cases.
max_nan_rows=0.8: This argument specifies the maximum percentage of rows that can contain missing values. If a row has more missing values than this threshold, it will be dropped from the input data.

Encode Categorical Features
# Encode the categorical features
atom.encode(strategy="Target", max_onehot=10, rare_to_value=0.04)

The code above demonstrates the use of the encode() method of the ATOMClassifier class to encode categorical features in the input data. We are passing in three arguments to the encode() method:
strategy="Target": This argument specifies the encoding strategy to use for categorical columns. In this case, we are using the target encoding strategy, which replaces each categorical value with the mean target value of the corresponding label. Target encoding can often provide better performance than one-hot encoding for high cardinality categorical variables.
max_onehot=10: This argument specifies the maximum number of unique categorical values allowed before a column is encoded using target encoding instead of one-hot encoding. This can help prevent the number of encoded columns from becoming too large.
rare_to_value=0.04: This argument specifies the threshold for rare categories. Categories that have a frequency lower than this threshold will be replaced with a new value. This helps to reduce the impact of rare categories on the model.

Model Training
# Train an Extra-Trees and a Random Forest model
atom.run(models=["ET", "RF"], metric="f1", n_bootstrap=5)
In the code above, we are training two machine learning models using the run() method of the ATOMClassifier class. The run() method takes in the following arguments:
models=["ET", "RF"]: This argument specifies the machine learning models to train. In this case, we are training an Extra-Trees model and a Random Forest model.
metric="f1": This argument specifies the performance metric to use for model evaluation. In this case, we are using the F1 score, which is a common metric for binary classification problems that balances precision and recall.
n_bootstrap=5: This argument specifies the number of bootstrapped samples to use for model evaluation. Bootstrapping is a resampling technique that can provide a more accurate estimate of model performance on unseen data.

Analyze the results
# Let's have a look at the final results
atom.results
The code above is using the results attribute of the ATOMClassifier class to display the final results of the model training and evaluation process. The results attribute provides a summary of the performance of each trained model on the test data. The output includes the following columns:
Model: The name of the trained model.
F1 Score: The F1 score of the model on the test data.
Precision: The precision of the model on the test data.
Recall: The recall of the model on the test data.
AUC ROC: The area under the receiver operating characteristic (ROC) curve of the model on the test data.

Visualize the results
# Visualize the bootstrap results
atom.plot_results(title="RF vs ET performance")
The code above is using the plot_results() method of the ATOMClassifier class to visualize the performance of the trained models using a box plot. The plot_results() method takes in the following arguments:
title="RF vs ET performance": This argument specifies the title of the plot.

The output of plot_results() is a box plot that displays the distribution of performance scores (F1 score in this case) across the bootstrapped samples for each trained model. The box plot allows for easy comparison of the performance of the two trained models, as well as visualization of the variability of the performance scores across the bootstrapped samples.

In conclusion, the ATOM ML module is a powerful and user-friendly library for building and evaluating machine learning models. It provides a variety of useful features and methods, including imputation of missing values, encoding of categorical features, and training and evaluation of models using a range of metrics.